{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Metrics Recipes\n",
    "\n",
    "In this page, we will show you how to customize your own metrics. In `carefree-learn`, it is fairly easy to define various kinds of metrics (ML, CV, etc.) with a unified API `register_metric`.\n",
    "\n",
    "> You might notice that if you run the blocks with `register_metric` calls for more than once, `carefree-learn` will throw a warning which says \" '...' has already been registered \", and your changes will have no effect. This is intentional because normally we **DO NOT** want to register anything for more than once.\n",
    "> \n",
    "> However, if you are using some interactive developing tools (e.g. Jupyter Notebook), it is very common to modify the implementations for more than once. In this case, we can set `allow_duplicate=True` in the `register_metric` functions to bypass this check. And of course, this should **NEVER** happen in production for safety!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "- [ML Metrics](#ML-Metrics)\n",
    "- [CV Metrics](#CV-Metrics)\n",
    "- [Complex Metrics](#Complex-Metrics)\n",
    "- [Integration](#Integration)\n",
    "  - [Single Metric](#Single-Metric)\n",
    "  - [Multiple Metrics](#Multiple-Metrics)\n",
    "  - [Weighted Metrics](#Weighted-Metrics)\n",
    "  - [Use Losses as Metrics](#Use-Losses-as-Metrics)\n",
    "- [Q&A](#Q&A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You might also notice that:\n",
    "> - All classes have inherited `MetricInterface`. This is not required, but it can guide you to implement the essential parts in IDE.\n",
    "> - The class name defined below somehow matches the registered name. This is also not required, since `carefree-learn` only cares about the name that you pass to the `register_metric` function, and will not check the actual class name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import cflearn\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Dict\n",
    "from cftool.array import iou\n",
    "from cftool.array import corr\n",
    "from cftool.array import softmax\n",
    "\n",
    "try:\n",
    "    from sklearn import metrics\n",
    "except:\n",
    "    metrics = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical classification metric\n",
    "@cflearn.register_metric(\"my_binary_accuracy\", allow_duplicate=False)\n",
    "class MyBinaryAccuracy(cflearn.MetricInterface):\n",
    "    def __init__(self, threshold: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # True means that the larger this metric is, the better.\n",
    "    @property\n",
    "    def is_positive(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    # logits : [N, 1]\n",
    "    # labels : [N, 1]\n",
    "    def forward(self, logits: np.ndarray, labels: np.ndarray) -> float:\n",
    "        predictions = (logits > self.threshold).astype(int)\n",
    "        return (predictions == labels).mean().item()\n",
    "\n",
    "# typical regression metric\n",
    "@cflearn.register_metric(\"my_l1\", allow_duplicate=False)\n",
    "class MyL1(cflearn.MetricInterface):\n",
    "    # False means that the smaller this metric is, the better.\n",
    "    @property\n",
    "    def is_positive(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    # predictions : [N, 1]\n",
    "    # labels      : [N, 1]\n",
    "    def forward(self, predictions: np.ndarray, labels: np.ndarray) -> float:\n",
    "        return np.abs(predictions - labels).mean().item()\n",
    "    \n",
    "# special classification metric, which requires the whole dataset to evaluate.\n",
    "@cflearn.register_metric(\"my_auc\", allow_duplicate=False)\n",
    "class MyAUC(cflearn.MetricInterface):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        if metrics is None:\n",
    "            print(\"`scikit-learn` needs to be installed for `AUC`\")\n",
    "\n",
    "    # True means that the larger this metric is, the better.\n",
    "    @property\n",
    "    def is_positive(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    #   True means that this metric requires the entire dataset to evaluate.\n",
    "    #   For AUC, this has to be True because for some imbalanced dataset, it is \n",
    "    # very likely to have some batches that only contain one kind of labels, which \n",
    "    # will crash the AUC calculation.\n",
    "    #   Notice that this is only useful when this metric is integrated in `carefree-learn`'s \n",
    "    # pipeline, where `carefree-learn` will read this flag and decide whether to pass\n",
    "    # the entire dataset to this metric or not.\n",
    "    @property\n",
    "    def requires_all(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    # K >= 2\n",
    "    # logits : [N, K]\n",
    "    # labels : [N, 1]\n",
    "    def forward(self, logits: np.ndarray, labels: np.ndarray) -> float:\n",
    "        if metrics is None:\n",
    "            return 0.0\n",
    "        num_classes = logits.shape[1]  # K\n",
    "        probabilities = softmax(logits)\n",
    "        labels = labels.ravel()\n",
    "        if num_classes == 2:\n",
    "            return metrics.roc_auc_score(labels, probabilities[..., 1])\n",
    "        return metrics.roc_auc_score(labels, probabilities, multi_class=\"ovr\")\n",
    "\n",
    "# special regression metric, which requires the whole dataset to evaluate.\n",
    "@cflearn.register_metric(\"my_corr\", allow_duplicate=False)\n",
    "class MyCorrelation(cflearn.MetricInterface):\n",
    "    # True means that the larger this metric is, the better.\n",
    "    @property\n",
    "    def is_positive(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    #   True means that this metric requires the entire dataset to evaluate.\n",
    "    #   For correlation, it is better to set it to True because correlation works better\n",
    "    # with more data. But this is kind of a trade-off: requiring the full dataset can\n",
    "    # indeed increase the accuracy of correlation estimation, but will also have much\n",
    "    # greater impact on your RAM.\n",
    "    @property\n",
    "    def requires_all(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    # predictions : [N, K]\n",
    "    # labels      : [N, K]\n",
    "    def forward(self, predictions: np.ndarray, labels: np.ndarray) -> float:\n",
    "        return corr(predictions, labels, get_diagonal=True).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.010000000000000007\n",
      "1.0\n",
      "0.9577071316741769\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "logits = np.random.random([100, 1]) - 0.5\n",
    "labels = (logits > 0).astype(int)\n",
    "my_binary_accuracy = cflearn.api.make_metric(\"my_binary_accuracy\")\n",
    "print(my_binary_accuracy.core.forward(logits, labels))\n",
    "\n",
    "predictions = np.random.random([100, 1])\n",
    "labels = predictions - 0.01\n",
    "my_l1 = cflearn.api.make_metric(\"my_l1\")\n",
    "print(my_l1.core.forward(predictions, labels))\n",
    "\n",
    "logits = np.random.random([100, 2])\n",
    "labels = np.argmax(logits, axis=1, keepdims=True)\n",
    "my_auc = cflearn.api.make_metric(\"my_auc\")\n",
    "print(my_auc.core.forward(logits, labels))\n",
    "logits = np.random.random([100, 10])\n",
    "labels = np.argmax(logits, axis=1, keepdims=True)\n",
    "print(my_auc.core.forward(logits, labels))\n",
    "logits[range(100), labels.ravel()] += 1.0\n",
    "print(my_auc.core.forward(logits, labels))\n",
    "\n",
    "predictions = np.random.random([100, 1])\n",
    "labels = predictions - 0.01\n",
    "my_corr = cflearn.api.make_metric(\"my_corr\")\n",
    "print(my_corr.core.forward(predictions, labels))\n",
    "predictions = np.random.random([100, 10])\n",
    "labels = predictions - 0.01\n",
    "print(my_corr.core.forward(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Metrics\n",
    "\n",
    "> For **C**omputer **V**ision metrics, if the metric is image-based, we should never set its `requires_all` to `True` because it will be a disaster to put all your images to RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection over Union, only supports binary situations\n",
    "@cflearn.register_metric(\"my_iou\", allow_duplicate=False)\n",
    "class MyIOU(cflearn.MetricInterface):\n",
    "    # True means that the larger this metric is, the better.\n",
    "    @property\n",
    "    def is_positive(self) -> bool:\n",
    "        return True\n",
    "    \n",
    "    # K âˆˆ {1, 2}\n",
    "    # logits : [N, K, H, W]\n",
    "    # labels : [N, 1, H, W]\n",
    "    def forward(self, logits: np.ndarray, labels: np.ndarray) -> float:\n",
    "        return iou(logits, labels).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3886738047599308\n",
      "0.575562001419822\n",
      "0.9866733849041874\n",
      "0.9999090014271987\n",
      "1.0\n",
      "0.575562001419822\n",
      "0.9866733849041874\n",
      "0.9999090014271987\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "logits = np.random.random([4, 2, 224, 224])\n",
    "labels = (logits[:, [1]] > 0.5).astype(int)\n",
    "concat = np.concatenate([1 - labels, labels], axis=1)\n",
    "my_iou = cflearn.api.make_metric(\"my_iou\")\n",
    "print(my_iou.core.forward(logits, labels))\n",
    "print(my_iou.core.forward(concat, labels))\n",
    "print(my_iou.core.forward(concat * 5, labels))\n",
    "print(my_iou.core.forward(concat * 10, labels))\n",
    "print(my_iou.core.forward(concat * 50, labels))\n",
    "print(my_iou.core.forward((labels - 0.5) * 2, labels))\n",
    "print(my_iou.core.forward((labels - 0.5) * 10, labels))\n",
    "print(my_iou.core.forward((labels - 0.5) * 20, labels))\n",
    "print(my_iou.core.forward((labels - 0.5) * 100, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Metrics\n",
    "\n",
    "In some complex situations, our predictions / inputs may have multiple values (e.g. multi-task problems). `carefree-learn` supports your custom metrics receiving a `dict` of `np.ndarray`s for such cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@cflearn.register_metric(\"my_complex_metric\", allow_duplicate=False)\n",
    "class MyComplexMetric(cflearn.MetricInterface):\n",
    "    @property\n",
    "    def is_positive(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        np_outputs: Dict[str, np.ndarray],\n",
    "        np_batch: Dict[str, np.ndarray],\n",
    "    ) -> float:\n",
    "        # do something\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naming is important here - you should use `np_outputs` & `np_batch` to let `carefree-learn` knows that you require the full data instead of one single `np.ndarray`.\n",
    "\n",
    "You can also simplify your implementation with this design if you only require parts of the full data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@cflearn.register_metric(\"my_complex_metric2\", allow_duplicate=False)\n",
    "class MyComplexMetric2(cflearn.MetricInterface):\n",
    "    @property\n",
    "    def is_positive(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        predictions: np.ndarray,\n",
    "        np_batch: Dict[str, np.ndarray],\n",
    "    ) -> float:\n",
    "        # do something\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some rare scenarios, we may even need the entire `DataLoader` to calculate our metrics. This is also accessible in `carefree-learn` by simply add a `loader` argument to the `forward` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@cflearn.register_metric(\"my_metric_with_loader\", allow_duplicate=False)\n",
    "class MyMetricWithLoader(cflearn.MetricInterface):\n",
    "    @property\n",
    "    def is_positive(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def forward(self, logits, labels, loader) -> float:\n",
    "        # do something\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration\n",
    "\n",
    "After defining our own metrics, we need to know how to integrate them in existing `carefree-learn` pipelines for training, testing and deploying. Basically, metrics could be specified across various APIs with `metric_names` and `metric_configs`. We will use `fit_ml` to demonstrate the core concepts, and the same recipes could be applied elsewhere.\n",
    "\n",
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random([100, 5])\n",
    "y = np.random.randint(0, 2, [100, 1])\n",
    "common_kwargs = dict(\n",
    "    x_train=x,\n",
    "    y_train=y,\n",
    "    x_valid=x,\n",
    "    y_valid=y,\n",
    "    core_name=\"linear\",\n",
    "    input_dim=5,\n",
    "    output_dim=2,\n",
    "    is_classification=True,\n",
    "    fixed_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Metric\n",
    "\n",
    "In this case, the `metric_names` should be an `str`, and the `metric_configs` should be the `kwargs` that will be passed to your metric's `__init__` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>> MyFooMetric.foo: 1.2345\n",
      "\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-075121\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.051s] | my_foo_metric : 1.234500 | score : 1.234500 |\n"
     ]
    }
   ],
   "source": [
    "@cflearn.register_metric(\"my_foo_metric\", allow_duplicate=False)\n",
    "class MyFooMetric(cflearn.MetricInterface):\n",
    "    def __init__(self, foo):\n",
    "        super().__init__()\n",
    "        self.foo = foo\n",
    "        print(f\"\\n>>>>>> MyFooMetric.foo: {foo}\\n\")\n",
    "\n",
    "    @property\n",
    "    def is_positive(self):\n",
    "        return True\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        return self.foo\n",
    "\n",
    "\n",
    "m = cflearn.api.fit_ml(\n",
    "    metric_names=\"my_foo_metric\",\n",
    "    metric_configs=dict(foo=1.2345),\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You might notice that `carefree-learn` will print out the metrics and the final score of current model. The final score is simply a 'mean' of every metric, except that the metrics with `is_positive=False` will be the opposite during the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>> MyFooNegativeMetric.foo: 1.2345\n",
      "\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-168124\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.011s] | my_foo_negative_metric : 1.234500 | score : -1.23450 |\n"
     ]
    }
   ],
   "source": [
    "@cflearn.register_metric(\"my_foo_negative_metric\", allow_duplicate=False)\n",
    "class MyFooNegativeMetric(cflearn.MetricInterface):\n",
    "    def __init__(self, foo):\n",
    "        super().__init__()\n",
    "        self.foo = foo\n",
    "        print(f\"\\n>>>>>> MyFooNegativeMetric.foo: {foo}\\n\")\n",
    "\n",
    "    @property\n",
    "    def is_positive(self):\n",
    "        return False\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        return self.foo\n",
    "\n",
    "\n",
    "m = cflearn.api.fit_ml(\n",
    "    metric_names=\"my_foo_negative_metric\",\n",
    "    metric_configs=dict(foo=1.2345),\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As shown above, the final score is now negative. For detailed explanation, please refer to the [Weighted Metrics](#Weighted-Metrics) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Metrics\n",
    "\n",
    "In this case, the `metric_names` should be a list of `str`, and the `metric_configs` should be a `dict`, where the keys are the names and the values will be passed to the corresponding `__init__` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>> MyFooMetric.foo: 1.2345\n",
      "\n",
      "\n",
      ">>>>>> MyBarMetric.bar: 2.3456\n",
      "\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-212127\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.012s] | my_bar_metric : 2.345600 | my_foo_metric : 1.234500 | score : 1.790050 |\n"
     ]
    }
   ],
   "source": [
    "@cflearn.register_metric(\"my_bar_metric\", allow_duplicate=False)\n",
    "class MyFooMetric(cflearn.MetricInterface):\n",
    "    def __init__(self, bar):\n",
    "        super().__init__()\n",
    "        self.bar = bar\n",
    "        print(f\"\\n>>>>>> MyBarMetric.bar: {bar}\\n\")\n",
    "\n",
    "    @property\n",
    "    def is_positive(self):\n",
    "        return True\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        return self.bar\n",
    "\n",
    "\n",
    "m = cflearn.api.fit_ml(\n",
    "    metric_names=[\"my_foo_metric\", \"my_bar_metric\"],\n",
    "    metric_configs=dict(\n",
    "        my_foo_metric=dict(foo=1.2345),\n",
    "        my_bar_metric=dict(bar=2.3456),\n",
    "    ),\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Metrics\n",
    "\n",
    "`carefree-learn` also supports weighted metrics. The formula under the hood is:\n",
    "\n",
    "$$\n",
    "\\text{score}=\\frac1{\\sum_{i=1}^{k}w_i}\\cdot\\sum_{i=1}^{k}\\hat m_i(\\hat y, y)\\cdot w_i\n",
    "$$\n",
    "\n",
    "the default value of $w_i$ is $1$, and\n",
    "\n",
    "$$\n",
    "\\hat m_i(\\hat y, y)\\triangleq I(\\text m_i)\\cdot \\text{m}_i\\text{.forward}(\\hat y, y)\n",
    "$$\n",
    "\n",
    "where $\\text m_i$ is the $i$th metric, and\n",
    "\n",
    "$$\n",
    "I(\\text m_i)\\triangleq\n",
    "\\begin{cases}\n",
    " 1, & \\text{if m}_i\\text{.is_positive} \\\\\n",
    " -1, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In order to use weighted metrics, we can specify `metric_weights`, where the keys are the metric names and the values are the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>> MyFooMetric.foo: 1.2345\n",
      "\n",
      "\n",
      ">>>>>> MyBarMetric.bar: 2.3456\n",
      "\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-255122\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.017s] | my_bar_metric : 2.345600 | my_foo_metric : 1.234500 | score : 1.962784 |\n",
      ">>> target score 1.9627840336134459\n"
     ]
    }
   ],
   "source": [
    "m = cflearn.api.fit_ml(\n",
    "    metric_names=[\"my_foo_metric\", \"my_bar_metric\"],\n",
    "    metric_configs=dict(\n",
    "        my_foo_metric=dict(foo=1.2345),\n",
    "        my_bar_metric=dict(bar=2.3456),\n",
    "    ),\n",
    "    metric_weights=dict(\n",
    "        my_foo_metric=0.123,\n",
    "        my_bar_metric=0.234,\n",
    "    ),\n",
    "    **common_kwargs,\n",
    ")\n",
    "\n",
    "print(\">>> target score\", (1.2345 * 0.123 + 2.3456 * 0.234) / (0.123 + 0.234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Losses as Metrics\n",
    "\n",
    "Sometimes it is enough to simply use losses as our metrics. `carefree-learn` provided `use_losses_as_metrics` flag for such cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-302126\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.011s] | loss : 0.220618 | score : -0.22061 |\n"
     ]
    }
   ],
   "source": [
    "m = cflearn.api.fit_ml(\n",
    "    use_losses_as_metrics=True,\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple losses are used, we can further specify `loss_metrics_weights` to indicates the weights.\n",
    "\n",
    "> - If `loss_metrics_weights` is not provided, only the final loss will be considered.\n",
    "> - If the loss's name does not occur in the `loss_metrics_weights`, it will not be included in the metric calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-349123\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.012s] | cross_entropy : 0.763204 | focal : 0.272475 | loss : 1.035679 | score : -1.03567 |\n"
     ]
    }
   ],
   "source": [
    "# only the final loss will present in the score\n",
    "m = cflearn.api.fit_ml(\n",
    "    loss_name=\"multi_task:focal,cross_entropy\",\n",
    "    use_losses_as_metrics=True,\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-398128\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.012s] | cross_entropy : 0.723179 | focal : 0.214762 | loss : 0.937942 | score : -0.21476 |\n"
     ]
    }
   ],
   "source": [
    "# only the `focal` loss will present in the score\n",
    "m = cflearn.api.fit_ml(\n",
    "    loss_name=\"multi_task:focal,cross_entropy\",\n",
    "    use_losses_as_metrics=True,\n",
    "    loss_metrics_weights=dict(focal=1.0),\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-445124\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.014s] | cross_entropy : 0.876756 | focal : 0.453641 | loss : 1.330397 | score : -0.54131 |\n"
     ]
    }
   ],
   "source": [
    "# both losses will present in the score\n",
    "m = cflearn.api.fit_ml(\n",
    "    loss_name=\"multi_task:focal,cross_entropy\",\n",
    "    use_losses_as_metrics=True,\n",
    "    loss_metrics_weights=dict(focal=1.0, cross_entropy=0.1),\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth mentioning that `use_losses_as_metrics` can be used with other metrics as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    Linear                                   [-1, 5]                                  [-1, 2]                   12\n",
      "      Linear                                 [-1, 5]                                  [-1, 2]                   12\n",
      "========================================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-07-23_16-55-35-496126\\checkpoints\n",
      "| epoch  -1  [-1 / 1] [0.015s] | acc : 0.550000 | auc : 0.549419 | cross_entropy : 0.689526 | focal : 0.181443 | loss : 0.870970 | score : 0.149656 |\n"
     ]
    }
   ],
   "source": [
    "m = cflearn.api.fit_ml(\n",
    "    metric_names=[\"acc\", \"auc\"],\n",
    "    loss_name=\"multi_task:focal,cross_entropy\",\n",
    "    use_losses_as_metrics=True,\n",
    "    loss_metrics_weights=dict(focal=1.0, cross_entropy=0.1),\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A\n",
    "\n",
    "## Does the order of the `forward` arguments matter?\n",
    "\n",
    "- Yes, it matters, we should always use `predictions` as the first argument, and `inputs` as the second. This is aligned to the `pytorch`'s API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
