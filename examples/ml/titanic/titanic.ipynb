{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic\n",
    "\n",
    "`Titanic` is a famous playground competition hosted by Kaggle ([here](https://www.kaggle.com/c/titanic)), so I'll simply copy-paste its brief description here:\n",
    "\n",
    "> This is the legendary Titanic ML competition â€“ the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n",
    "> \n",
    "> The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n",
    "\n",
    "Here are the frist few rows of the `train.csv` of `Titanic`:\n",
    "\n",
    "```csv\n",
    "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n",
    "2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n",
    "3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\n",
    "```\n",
    "\n",
    "And the first few rows of the `test.csv`:\n",
    "\n",
    "```csv\n",
    "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q\n",
    "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S\n",
    "894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q\n",
    "```\n",
    "\n",
    "What we need to do is to predict the `Survived` column in `test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparations\n",
    "\n",
    "import torch\n",
    "import cflearn\n",
    "import numpy as np\n",
    "from cflearn.toolkit import seed_everything\n",
    "\n",
    "# for reproduction\n",
    "seed_everything(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Data\n",
    "\n",
    "Since the target column is not the last column (which is the default setting of `carefree-learn`), we need to manually configure it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_config = cflearn.MLBundledProcessorConfig(label_names=[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you're all set! Notice that only the `label_name` needs to be provided, and `carefree-learn` will find out the corresponding target column for youðŸ˜‰\n",
    "\n",
    "> - Notice that we can directly pass in a file and `carefree-learn` will handle everything for you (*file-in*).\n",
    ">\n",
    "> - We also specified `num_split=200`, which means we will randomly pick `50` samples for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [warning] values in int column 'PassengerId' are ALL DIFFERENT. It'll be marked as redundant.\n",
      "> [warning] values in string column 'Name' are ALL DIFFERENT. It'll be marked as redundant.\n",
      "> [warning] values in string column 'Ticket' are TOO MANY (ratio=0.764310). It'll be marked as redundant.\n"
     ]
    }
   ],
   "source": [
    "data = cflearn.MLData.init(processor_config=processor_config).fit(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `carefree-learn` can do some auto data preprocessing: it detects three columns that might be redundant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Your Model\n",
    "\n",
    "For instance, we'll use the famous `Wide & Deep` model. First, we need to define the `config`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cflearn.MLConfig(\n",
    "    module_name=\"wnd\",\n",
    "    module_config=dict(input_dim=data.num_features, output_dim=1),\n",
    "    loss_name=\"bce\",\n",
    "    metric_names=[\"acc\", \"auc\"],\n",
    "    # use nesterov SGD optimizer\n",
    "    lr=0.1,\n",
    "    optimizer_name=\"sgd\",\n",
    "    optimizer_config=dict(nesterov=True, momentum=0.9),\n",
    "    # set embedding dim to 8\n",
    "    global_encoder_settings=cflearn.MLGlobalEncoderSettings(embedding_dim=8),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we used `data.num_features`, which will tell the model what the (original) number of features is.\n",
    "\n",
    "With this `config`, building model is just one-line-code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================\n",
      "                                    Internal Default Configurations Used by `carefree-learn`                                    \n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                   train_samples   |   791\n",
      "                                                   valid_samples   |   100\n",
      "                                               max_snapshot_file   |   25\n",
      "                                          encoder_settings.1.dim   |   3\n",
      "                                      encoder_settings.1.methods   |   embedding\n",
      "                               encoder_settings.1.method_configs   |   None\n",
      "                                          encoder_settings.3.dim   |   2\n",
      "                                      encoder_settings.3.methods   |   embedding\n",
      "                               encoder_settings.3.method_configs   |   None\n",
      "                                          encoder_settings.5.dim   |   7\n",
      "                                      encoder_settings.5.methods   |   embedding\n",
      "                               encoder_settings.5.method_configs   |   None\n",
      "                                          encoder_settings.6.dim   |   7\n",
      "                                      encoder_settings.6.methods   |   embedding\n",
      "                               encoder_settings.6.method_configs   |   None\n",
      "                                          encoder_settings.9.dim   |   148\n",
      "                                      encoder_settings.9.methods   |   embedding\n",
      "                               encoder_settings.9.method_configs   |   None\n",
      "                                         encoder_settings.10.dim   |   4\n",
      "                                     encoder_settings.10.methods   |   embedding\n",
      "                              encoder_settings.10.method_configs   |   None\n",
      "                                                 index_mapping.1   |   0\n",
      "                                                 index_mapping.3   |   1\n",
      "                                                 index_mapping.4   |   2\n",
      "                                                 index_mapping.5   |   3\n",
      "                                                 index_mapping.6   |   4\n",
      "                                                 index_mapping.8   |   5\n",
      "                                                 index_mapping.9   |   6\n",
      "                                                index_mapping.10   |   7\n",
      "                                                       workspace   |   _logs/2023-12-03_12-07-25-161446\n",
      "                                                   monitor_names   |   ['mean_std', 'plateau']\n",
      "                                            additional_callbacks   |   ['_log_metrics_msg']\n",
      "                                         log_metrics_msg_verbose   |   True\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "================================================================================================================================\n",
      "                                                    External Configurations                                                     \n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                           model   |   ml.wnd\n",
      "                                                     module_name   |   wnd\n",
      "                                         module_config.input_dim   |   8\n",
      "                                        module_config.output_dim   |   1\n",
      "                                  state_config.max_snapshot_file   |   25\n",
      "                              state_config.num_step_per_snapshot   |   3\n",
      "                                state_config.snapshot_start_step   |   24\n",
      "                                                    metric_names   |   ['acc', 'auc']\n",
      "                                                  callback_names   |   ['_log_metrics_msg']\n",
      "                       callback_configs._log_metrics_msg.verbose   |   True\n",
      "                                                              lr   |   0.1\n",
      "                                                  optimizer_name   |   sgd\n",
      "                                       optimizer_config.nesterov   |   True\n",
      "                                       optimizer_config.momentum   |   0.9\n",
      "                                             optimizer_config.lr   |   0.03333333333333333\n",
      "                                optimizer_settings.all.optimizer   |   sgd\n",
      "                                optimizer_settings.all.scheduler   |   None\n",
      "                         optimizer_settings.all.optimizer_config   |   {'nesterov': True, 'momentum': 0.9, 'lr': 0.03333333333333333}\n",
      "                         optimizer_settings.all.scheduler_config   |   None\n",
      "                                          tqdm_settings.use_tqdm   |   False\n",
      "                                     tqdm_settings.use_step_tqdm   |   False\n",
      "                            tqdm_settings.use_tqdm_in_validation   |   False\n",
      "                                    tqdm_settings.in_distributed   |   False\n",
      "                                     tqdm_settings.tqdm_position   |   0\n",
      "                                         tqdm_settings.tqdm_desc   |   epoch\n",
      "                                                       loss_name   |   bce\n",
      "                           global_encoder_settings.embedding_dim   |   8\n",
      "                       global_encoder_settings.embedding_dropout   |   None\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ModuleDict                                                                                                        \n",
      "  Encoder                                    [-1, 8]                      1.          [-1, 6]                1,368\n",
      "                                                                          2.         [-1, 48]                     \n",
      "    ModuleDict-0                                                                                                  \n",
      "      Embedding-0                               [-1]                                  [-1, 8]                   24\n",
      "        Dropout                              [-1, 8]                                  [-1, 8]                    0\n",
      "      Embedding-1                               [-1]                                  [-1, 8]                   16\n",
      "        Dropout                              [-1, 8]                                  [-1, 8]                    0\n",
      "      Embedding-2                               [-1]                                  [-1, 8]                   56\n",
      "        Dropout                              [-1, 8]                                  [-1, 8]                    0\n",
      "      Embedding-3                               [-1]                                  [-1, 8]                   56\n",
      "        Dropout                              [-1, 8]                                  [-1, 8]                    0\n",
      "      Embedding-4                               [-1]                                  [-1, 8]                1,184\n",
      "        Dropout                              [-1, 8]                                  [-1, 8]                    0\n",
      "      Embedding-5                               [-1]                                  [-1, 8]                   32\n",
      "        Dropout                              [-1, 8]                                  [-1, 8]                    0\n",
      "  WideAndDeep                               [-1, 48]                                  [-1, 1]               15,350\n",
      "    Linear                                  [-1, 48]                                  [-1, 1]                   49\n",
      "    FCNN                                    [-1, 50]                                  [-1, 1]               15,301\n",
      "      Sequential                            [-1, 50]                                  [-1, 1]               15,301\n",
      "        Mapping-0                           [-1, 50]                                [-1, 100]                5,100\n",
      "          Linear                            [-1, 50]                                [-1, 100]                5,100\n",
      "          ReLU                             [-1, 100]                                [-1, 100]                    0\n",
      "        Mapping-1                          [-1, 100]                                [-1, 100]               10,100\n",
      "          Linear                           [-1, 100]                                [-1, 100]               10,100\n",
      "          ReLU                             [-1, 100]                                [-1, 100]                    0\n",
      "        Linear                             [-1, 100]                                  [-1, 1]                  101\n",
      "========================================================================================================================\n",
      "Total params: 16,718\n",
      "Trainable params: 16,718\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  51  [1 / 7] [1.583s] | acc : 0.820000 | auc : 0.855475 | score : 0.837737 |\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      ">  [ info ] restoring from _logs/2023-12-03_12-07-25-161446/checkpoints/model_351.pt\n",
      "| epoch  -1  [-1 / 7] [0.391s] | acc : 0.820000 | auc : 0.855475 | score : 0.837737 |\n"
     ]
    }
   ],
   "source": [
    "m = cflearn.api.fit_ml(data, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Your Model\n",
    "\n",
    "After building the model, we can directly build a `loader` from a `file` to evaluate our model (*file-out*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricsOutputs(final_score=0.8588882304010288, metric_values={'acc': 0.8383838383838383, 'auc': 0.8793926224182194}, is_positive={'acc': True, 'auc': True})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = m.data.build_loader(\"train.csv\")\n",
    "m.evaluate(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieved an accuracy of `0.83389`, not bad!\n",
    "\n",
    "> Note that this performance is not exactly the *training* performance, because `carefree-learn` will automatically split out the cross validation dataset for you.\n",
    "\n",
    "### Making Predictions\n",
    "\n",
    "Again, we can directly build a `loader` from a `file` to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  [ info ] labels are not detected and `for_inference` is set to True, so `contain_labels` will be set to False\n",
      "> [warning] [PassengerId] OOD samples detected (418/418=1.000000), replaced with most frequent\n",
      "> [warning] [Name] OOD samples detected (416/418=0.995215), replaced with most frequent\n",
      "> [warning] [Parch] OOD samples detected (2/418=0.004785), replaced with most frequent\n",
      "> [warning] [Ticket] OOD samples detected (266/418=0.636364), replaced with most frequent\n",
      "> [warning] [Cabin] OOD samples detected (46/418=0.110048), replaced with empty string\n"
     ]
    }
   ],
   "source": [
    "loader = m.data.build_loader(\"test.csv\")\n",
    "predictions = m.predict(loader)[cflearn.PREDICTIONS_KEY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we detected that the `test.csv` does not contain labels, and handled it correctly!\n",
    "\n",
    "Apart from making raw predictions, we can also specify `carefree-learn` to return probabilities, or classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9015375  0.09846253]\n",
      " [0.7232104  0.2767896 ]\n",
      " [0.9253068  0.07469322]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = m.predict(loader, return_probabilities=True)[cflearn.PREDICTIONS_KEY]\n",
    "classes = m.predict(loader, return_classes=True)[cflearn.PREDICTIONS_KEY]\n",
    "print(probabilities[:3])\n",
    "print(classes[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Your Results\n",
    "\n",
    "If you reached here, we have actually already completed this `Titanic` task! All we need to do is to convert the `predictions` into a submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.csv\", \"r\") as f:\n",
    "    f.readline()\n",
    "    id_list = [line.strip().split(\",\")[0] for line in f]\n",
    "with open(\"submission.csv\", \"w\") as f:\n",
    "    f.write(\"PassengerId,Survived\\n\")\n",
    "    for test_id, c in zip(id_list, classes.ravel()):\n",
    "        f.write(f\"{test_id},{c.item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running these codes, a `submissions.csv` will be generated and you can submit it to Kaggle directly. In my personal experience, it could achieve 0.77751."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Since `Titanic` is just a small toy dataset, using Neural Network to solve it might actually 'over-killed' (or, overfit) it, and that's why we decided to conclude here instead of introducing more fancy techniques (e.g. ensemble, AutoML, etc.). We hope that this small example can help you quickly walk through some basic concepts in `carefre-learn`, as well as help you leverage `carefree-learn` in your own tasks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b0ddcce8366409cd7ed9aeeefe8a9e4bfb278beb4dd70cfb49c585a64703047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
